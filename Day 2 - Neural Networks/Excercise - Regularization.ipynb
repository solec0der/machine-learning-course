{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dsiag.ch/images/dsi_rgb.png\" alt=\"dsi logo\" width=\"100\" style=\"position: absolute; right: 0px;\"/>\n",
    "\n",
    "# Exercise: Regularization\n",
    "\n",
    "### Load Fashion MNIST Dataset\n",
    "\n",
    "Fashion-MNIST is a dataset of Zalandoâ€™s article images \n",
    "\n",
    "https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fashion mnist is integrated into tf.keras.datasets\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# define class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Put grayscale values between 0 and 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Convert Labels to One-Hot Encoding \n",
    "train_labels_one_hot = tf.one_hot(train_labels, len(class_names))\n",
    "test_labels_one_hot = tf.one_hot(test_labels, len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Tasks\n",
    "\n",
    "**1. Create a sequential feed forward tensorflow model with l2 regularization:**\n",
    "- the 28x28 input images are flattened to a vector\n",
    "- the internal layer contains 128 nodes and is activated with the RELU function and a **l2 kernel regularizer**\n",
    "- the output layer has ten output logits (one for each class in the one-hot encoded label)\n",
    "- the softmax function is applied to the logits\n",
    "- it uses a stochastic gradient descent optimizer with a categorical crossentropy loss function\n",
    "\n",
    "\n",
    "Train the model on the training data for 10 epochs: How good is the accuracy on the training data?\n",
    "    \n",
    "Evaluate your model: How good is the accuracy on the test data?\n",
    "\n",
    "**2.  Create a sequential feed forward tensorflow model with dropout regularization:**\n",
    "- the 28x28 input images are flattened to a vector\n",
    "- the internal layer contains 128 nodes and is activated with the RELU function\n",
    "- **two dropout layers regularize the model and prevent overfitting**\n",
    "- the output layer has ten output logits (one for each class in the one-hot encoded label)\n",
    "- the softmax function is applied to the logits\n",
    "- it uses a stochastic gradient descent optimizer with a categorical crossentropy loss function\n",
    "\n",
    "Train the model on the training data for 10 epochs: How good is the accuracy on the training data?\n",
    "    \n",
    "Evaluate your model: How good is the accuracy on the test data?\n",
    "\n",
    "**3. Compare the two regularization techniques, which one would you prefer?**\n",
    "\n",
    "**4. (Optional) Can you improve your model(s)?**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Links / References:\n",
    "\n",
    "- TensorFlow Quick Start for Beginners: https://www.tensorflow.org/tutorials/quickstart/beginner\n",
    "- TensorFlow Keras Classification https://www.tensorflow.org/tutorials/keras/classification\n",
    "- TensorFlow Overfit and Underfit https://www.tensorflow.org/tutorials/keras/overfit_and_underfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feed Forward Neural Net with l2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define model\n",
    "l2Model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "l2Model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "l2Model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 2s 756us/step - loss: 0.8642 - accuracy: 0.7934\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 1s 761us/step - loss: 0.6543 - accuracy: 0.8107\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 1s 784us/step - loss: 0.6318 - accuracy: 0.8167\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 1s 772us/step - loss: 0.6089 - accuracy: 0.8223\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 1s 763us/step - loss: 0.5916 - accuracy: 0.8259\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 1s 750us/step - loss: 0.5794 - accuracy: 0.8287\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 1s 747us/step - loss: 0.5645 - accuracy: 0.8335\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 1s 753us/step - loss: 0.5598 - accuracy: 0.8360\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 1s 762us/step - loss: 0.5557 - accuracy: 0.8359\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 1s 760us/step - loss: 0.5477 - accuracy: 0.8388\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 1s 750us/step - loss: 0.5429 - accuracy: 0.8400\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 1s 753us/step - loss: 0.5343 - accuracy: 0.8408\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 1s 769us/step - loss: 0.5298 - accuracy: 0.8443\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 1s 778us/step - loss: 0.5317 - accuracy: 0.8417\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 1s 758us/step - loss: 0.5248 - accuracy: 0.8437\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 1s 746us/step - loss: 0.5250 - accuracy: 0.8441\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 1s 734us/step - loss: 0.5188 - accuracy: 0.8446\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 1s 744us/step - loss: 0.5192 - accuracy: 0.8446\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 1s 745us/step - loss: 0.5186 - accuracy: 0.8442\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 1s 747us/step - loss: 0.5180 - accuracy: 0.8447\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 1s 751us/step - loss: 0.5174 - accuracy: 0.8442\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 1s 780us/step - loss: 0.5120 - accuracy: 0.8460\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 1s 775us/step - loss: 0.5150 - accuracy: 0.8456\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 1s 789us/step - loss: 0.5124 - accuracy: 0.8449\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 1s 775us/step - loss: 0.5118 - accuracy: 0.8467\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 1s 777us/step - loss: 0.5085 - accuracy: 0.8472\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 2s 805us/step - loss: 0.5102 - accuracy: 0.8458\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 2s 810us/step - loss: 0.5074 - accuracy: 0.8456\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 1s 786us/step - loss: 0.5073 - accuracy: 0.8461\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 1s 781us/step - loss: 0.5060 - accuracy: 0.8464\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2ddfacfa0>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "l2Model.fit(train_images, train_labels_one_hot, epochs=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.5755 - accuracy: 0.8128 - 158ms/epoch - 504us/step\n",
      "313/313 [==============================] - 0s 385us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[2.0736930e-05, 1.7025479e-06, 7.3970837e-06, ..., 3.9631811e-01,\n        1.6323115e-04, 4.5134342e-01],\n       [2.8443062e-03, 9.3030224e-09, 9.5105702e-01, ..., 6.2054977e-17,\n        2.4820949e-05, 1.7752392e-12],\n       [9.8315704e-06, 9.9998391e-01, 1.5340872e-06, ..., 3.4426714e-10,\n        2.9953927e-08, 6.6042576e-13],\n       ...,\n       [2.6600435e-01, 7.8347193e-06, 1.0628628e-02, ..., 1.0941106e-06,\n        6.0520869e-01, 5.8511637e-06],\n       [5.1299485e-06, 9.9972850e-01, 2.8920388e-07, ..., 6.1263535e-07,\n        1.2104543e-07, 1.4075777e-08],\n       [1.2343496e-04, 3.8417561e-06, 2.7144077e-04, ..., 2.4742501e-02,\n        9.1397995e-04, 6.3444447e-04]], dtype=float32)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "\n",
    "test_loss, test_acc = l2Model.evaluate(test_images,  test_labels_one_hot, verbose=2)\n",
    "\n",
    "l2Model.predict(test_images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feed Forward Neural Net with Dropout regularization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_19 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 64)                50240     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      " softmax_19 (Softmax)        (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "# Define model\n",
    "dropoutModel = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "dropoutModel.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "dropoutModel.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 1s 654us/step - loss: 0.5662 - accuracy: 0.8025\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 1s 623us/step - loss: 0.4196 - accuracy: 0.8497\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 1s 656us/step - loss: 0.3850 - accuracy: 0.8603\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 1s 624us/step - loss: 0.3637 - accuracy: 0.8674\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 1s 635us/step - loss: 0.3544 - accuracy: 0.8697\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 1s 629us/step - loss: 0.3400 - accuracy: 0.8757\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 1s 625us/step - loss: 0.3293 - accuracy: 0.8780\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 1s 621us/step - loss: 0.3233 - accuracy: 0.8798\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 1s 676us/step - loss: 0.3143 - accuracy: 0.8838\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 1s 663us/step - loss: 0.3087 - accuracy: 0.8862\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 1s 642us/step - loss: 0.3016 - accuracy: 0.8886\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 1s 634us/step - loss: 0.2972 - accuracy: 0.8906\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 1s 636us/step - loss: 0.2920 - accuracy: 0.8917\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 1s 626us/step - loss: 0.2894 - accuracy: 0.8922\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 1s 621us/step - loss: 0.2819 - accuracy: 0.8944\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 1s 657us/step - loss: 0.2806 - accuracy: 0.8954\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 1s 623us/step - loss: 0.2783 - accuracy: 0.8958\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 1s 622us/step - loss: 0.2737 - accuracy: 0.8961\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 1s 632us/step - loss: 0.2703 - accuracy: 0.8995\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 1s 628us/step - loss: 0.2669 - accuracy: 0.9006\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 1s 620us/step - loss: 0.2639 - accuracy: 0.9010\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 1s 630us/step - loss: 0.2635 - accuracy: 0.8996\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 1s 626us/step - loss: 0.2592 - accuracy: 0.9013\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 1s 630us/step - loss: 0.2585 - accuracy: 0.9021\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 1s 622us/step - loss: 0.2548 - accuracy: 0.9042\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 1s 624us/step - loss: 0.2541 - accuracy: 0.9047\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 1s 626us/step - loss: 0.2521 - accuracy: 0.9046\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 1s 632us/step - loss: 0.2481 - accuracy: 0.9065\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 1s 622us/step - loss: 0.2462 - accuracy: 0.9068\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 1s 626us/step - loss: 0.2422 - accuracy: 0.9096\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 1s 626us/step - loss: 0.2433 - accuracy: 0.9076\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 1s 636us/step - loss: 0.2412 - accuracy: 0.9067\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 1s 625us/step - loss: 0.2392 - accuracy: 0.9093\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 1s 627us/step - loss: 0.2367 - accuracy: 0.9117\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 1s 624us/step - loss: 0.2377 - accuracy: 0.9094\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 1s 628us/step - loss: 0.2361 - accuracy: 0.9106\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 1s 625us/step - loss: 0.2330 - accuracy: 0.9110\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 1s 638us/step - loss: 0.2302 - accuracy: 0.9131\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 1s 669us/step - loss: 0.2305 - accuracy: 0.9117\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 1s 643us/step - loss: 0.2257 - accuracy: 0.9125\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 1s 637us/step - loss: 0.2289 - accuracy: 0.9129\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 1s 633us/step - loss: 0.2249 - accuracy: 0.9137\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 1s 642us/step - loss: 0.2248 - accuracy: 0.9148\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 1s 635us/step - loss: 0.2239 - accuracy: 0.9144\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 1s 631us/step - loss: 0.2189 - accuracy: 0.9158\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 1s 632us/step - loss: 0.2210 - accuracy: 0.9150\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 1s 637us/step - loss: 0.2184 - accuracy: 0.9160\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 1s 646us/step - loss: 0.2173 - accuracy: 0.9160\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 1s 656us/step - loss: 0.2171 - accuracy: 0.9161\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 1s 649us/step - loss: 0.2155 - accuracy: 0.9175\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 1s 635us/step - loss: 0.2153 - accuracy: 0.9175\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 1s 644us/step - loss: 0.2125 - accuracy: 0.9186\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 1s 642us/step - loss: 0.2138 - accuracy: 0.9171\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 1s 637us/step - loss: 0.2107 - accuracy: 0.9195\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 1s 636us/step - loss: 0.2105 - accuracy: 0.9189\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 1s 638us/step - loss: 0.2111 - accuracy: 0.9187\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 1s 648us/step - loss: 0.2090 - accuracy: 0.9197\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 1s 643us/step - loss: 0.2087 - accuracy: 0.9190\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 1s 641us/step - loss: 0.2076 - accuracy: 0.9221\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 1s 674us/step - loss: 0.2043 - accuracy: 0.9213\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 1s 679us/step - loss: 0.2051 - accuracy: 0.9207\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 1s 687us/step - loss: 0.2054 - accuracy: 0.9197\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 1s 678us/step - loss: 0.2030 - accuracy: 0.9221\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 1s 675us/step - loss: 0.2013 - accuracy: 0.9219\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 1s 688us/step - loss: 0.2007 - accuracy: 0.9224\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 1s 679us/step - loss: 0.2003 - accuracy: 0.9232\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 1s 641us/step - loss: 0.2007 - accuracy: 0.9230\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 1s 580us/step - loss: 0.1999 - accuracy: 0.9243\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 1s 576us/step - loss: 0.1986 - accuracy: 0.9236\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 1s 573us/step - loss: 0.1974 - accuracy: 0.9234\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 1s 571us/step - loss: 0.1982 - accuracy: 0.9238\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 1s 573us/step - loss: 0.1950 - accuracy: 0.9251\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 1s 574us/step - loss: 0.1969 - accuracy: 0.9239\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 1s 576us/step - loss: 0.1941 - accuracy: 0.9249\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 1s 572us/step - loss: 0.1961 - accuracy: 0.9233\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 1s 579us/step - loss: 0.1932 - accuracy: 0.9252\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 1s 590us/step - loss: 0.1918 - accuracy: 0.9265\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 1s 594us/step - loss: 0.1931 - accuracy: 0.9261\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 1s 596us/step - loss: 0.1916 - accuracy: 0.9260\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 1s 614us/step - loss: 0.1915 - accuracy: 0.9254\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 1s 611us/step - loss: 0.1923 - accuracy: 0.9258\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 1s 607us/step - loss: 0.1893 - accuracy: 0.9276\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 1s 565us/step - loss: 0.1896 - accuracy: 0.9278\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 1s 569us/step - loss: 0.1871 - accuracy: 0.9274\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 1s 562us/step - loss: 0.1876 - accuracy: 0.9265\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 1s 561us/step - loss: 0.1878 - accuracy: 0.9268\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 1s 563us/step - loss: 0.1847 - accuracy: 0.9293\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 1s 562us/step - loss: 0.1880 - accuracy: 0.9267\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 1s 562us/step - loss: 0.1856 - accuracy: 0.9289\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 1s 567us/step - loss: 0.1838 - accuracy: 0.9292\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 1s 564us/step - loss: 0.1829 - accuracy: 0.9292\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 1s 562us/step - loss: 0.1818 - accuracy: 0.9304\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 1s 567us/step - loss: 0.1833 - accuracy: 0.9279\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 1s 559us/step - loss: 0.1841 - accuracy: 0.9296\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 1s 557us/step - loss: 0.1825 - accuracy: 0.9283\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 1s 560us/step - loss: 0.1810 - accuracy: 0.9289\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 1s 562us/step - loss: 0.1815 - accuracy: 0.9287\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 1s 560us/step - loss: 0.1791 - accuracy: 0.9301\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 1s 561us/step - loss: 0.1791 - accuracy: 0.9301\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 1s 563us/step - loss: 0.1780 - accuracy: 0.9319\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x33cccdb80>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "dropoutModel.fit(train_images, train_labels_one_hot, epochs=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.6707 - accuracy: 0.8861 - 124ms/epoch - 397us/step\n",
      "313/313 [==============================] - 0s 385us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[3.3070443e-33, 0.0000000e+00, 0.0000000e+00, ..., 1.0423998e-10,\n        0.0000000e+00, 1.0000000e+00],\n       [3.4867647e-14, 0.0000000e+00, 1.0000000e+00, ..., 0.0000000e+00,\n        1.4910449e-26, 0.0000000e+00],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00],\n       ...,\n       [6.5609187e-29, 0.0000000e+00, 6.4767921e-37, ..., 0.0000000e+00,\n        1.0000000e+00, 0.0000000e+00],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00],\n       [4.9685348e-15, 0.0000000e+00, 1.8933569e-27, ..., 5.3921558e-06,\n        3.3581203e-13, 2.8084856e-21]], dtype=float32)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "\n",
    "test_loss, test_acc = dropoutModel.evaluate(test_images,  test_labels_one_hot, verbose=2)\n",
    "\n",
    "dropoutModel.predict(test_images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}