{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dsiag.ch/images/dsi_rgb.png\" alt=\"dsi logo\" width=\"100\" style=\"position: absolute; right: 0px;\"/>\n",
    "\n",
    "# Exercise: Convolutional Neural Network \n",
    "\n",
    "### Load Fashion MNIST Dataset\n",
    "\n",
    "Fashion-MNIST is a dataset of Zalandoâ€™s article images \n",
    "\n",
    "https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fashion mnist is integrated into tf.keras.datasets\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# define class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Put grayscale values between 0 and 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Convert Labels to One-Hot Encoding \n",
    "train_labels_one_hot = tf.one_hot(train_labels, len(class_names))\n",
    "test_labels_one_hot = tf.one_hot(test_labels, len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 3D Images\n",
    "\n",
    "Convolutional neural networks in tensorflow require a 3d image as input. Therefore we reshape our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_3d = train_images.reshape(train_images.shape[0], train_images.shape[1], train_images.shape[2], 1)\n",
    "test_images_3d = test_images.reshape(test_images.shape[0], test_images.shape[1], test_images.shape[2], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Tasks\n",
    "\n",
    "**1. Create a CNN tensorflow model:**\n",
    "\n",
    "- Input convolution with 28 filters and kernel size 3x3\n",
    "- Max pooling operation with pool size 2x2\n",
    "- Internal convolution layer followed by a corresponding internal dense neural network layer\n",
    "- Dense output layer to reach 10 logits to which the softmax function is applied\n",
    "- A stochastic gradient descent optimizer with a categorical crossentropy loss function\n",
    "\n",
    "How many trainable parameters has this model?\n",
    "\n",
    "Train the model on the training data for 10 epochs: How good is the accuracy on the training data?\n",
    "    \n",
    "Evaluate your model: How good is the accuracy on the test data?\n",
    "\n",
    "**3. Compare it to the previous models. Which one would you prefer?**\n",
    "\n",
    "**4. (Optional) Can you improve your model?**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Links / References:\n",
    "\n",
    "- TensorFlow CNN Tutorial https://www.tensorflow.org/tutorials/images/cnn\n",
    "- Conv2d  https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
    "- MaxPool2d https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 26, 26, 28)        280       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 13, 13, 28)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 11, 11, 128)       32384     \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 15488)             0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 128)               1982592   \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      " softmax_12 (Softmax)        (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,016,546\n",
      "Trainable params: 2,016,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=28, kernel_size=(3,3),input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(56, 3, activation=\"relu\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(56, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.3756 - accuracy: 0.8646\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2471 - accuracy: 0.9092\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.1926 - accuracy: 0.9286\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.1530 - accuracy: 0.9428\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.1192 - accuracy: 0.9554\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0968 - accuracy: 0.9634\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0760 - accuracy: 0.9713\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0617 - accuracy: 0.9771\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0483 - accuracy: 0.9825\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0427 - accuracy: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x3059c74f0>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "model.fit(train_images_3d, train_labels_one_hot, epochs=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.4339 - accuracy: 0.9123 - 1s/epoch - 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[7.1705992e-16, 1.4640052e-15, 6.3536199e-17, ..., 7.4980595e-12,\n        8.6895954e-19, 1.0000000e+00],\n       [5.4532887e-18, 2.0716456e-24, 1.0000000e+00, ..., 6.2685696e-23,\n        6.7137165e-21, 6.3523163e-23],\n       [1.9750463e-22, 1.0000000e+00, 1.8583497e-32, ..., 8.3398747e-37,\n        3.9012771e-25, 2.6386065e-34],\n       ...,\n       [2.2465251e-20, 2.0605688e-27, 1.1408263e-21, ..., 2.6460198e-23,\n        1.0000000e+00, 1.8995578e-29],\n       [8.4097608e-18, 1.0000000e+00, 2.2116095e-22, ..., 4.7409042e-24,\n        1.2311269e-18, 1.1368567e-19],\n       [5.3134128e-05, 1.1141947e-07, 3.7016028e-07, ..., 5.3299099e-02,\n        1.5541904e-05, 6.6036337e-06]], dtype=float32)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images_3d,  test_labels_one_hot, verbose=2)\n",
    "\n",
    "model.predict(test_images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}